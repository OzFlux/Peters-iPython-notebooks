{
 "metadata": {
  "name": "",
  "signature": "sha256:2ba45e8206638f2fb61a97b321ecb211c4d71d4658c88215f55eabf8bcf8778d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run basics\n",
      "import datetime\n",
      "import glob\n",
      "import xlrd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xlname = \"../../AWS/Locations/AWS_Locations.xls\"\n",
      "wb = xlrd.open_workbook(xlname)\n",
      "sheet = wb.sheet_by_name(\"OzFlux\")\n",
      "xl_row = 10\n",
      "xl_col = 0\n",
      "bom_sites_info = {}\n",
      "for n in range(xl_row,sheet.nrows):\n",
      "    xlrow = sheet.row_values(n)\n",
      "    bom_sites_info[str(xlrow[0])] = {}\n",
      "    bom_sites_info[xlrow[0]][\"latitude\"] = xlrow[1]\n",
      "    bom_sites_info[xlrow[0]][\"longitude\"] = xlrow[2]\n",
      "    bom_sites_info[xlrow[0]][\"elevation\"] = xlrow[3]\n",
      "    for i in [4,10,16,22]:\n",
      "        if xlrow[i]!=\"\":\n",
      "            bom_sites_info[str(xlrow[0])][str(int(xlrow[i+1]))] = {}\n",
      "            bom_sites_info[str(xlrow[0])][str(int(xlrow[i+1]))][\"site_name\"] = xlrow[i]\n",
      "            bom_sites_info[str(xlrow[0])][str(int(xlrow[i+1]))][\"latitude\"] = xlrow[i+2]\n",
      "            bom_sites_info[str(xlrow[0])][str(int(xlrow[i+1]))][\"longitude\"] = xlrow[i+3]\n",
      "            bom_sites_info[str(xlrow[0])][str(int(xlrow[i+1]))][\"elevation\"] = xlrow[i+4]\n",
      "            bom_sites_info[str(xlrow[0])][str(int(xlrow[i+1]))][\"distance\"] = xlrow[i+5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "in_path = \"../../AWS/30MinuteMeteorology/\"\n",
      "in_filename = in_path+\"HM01X_Data*.txt\"\n",
      "file_list = sorted(glob.glob(in_filename))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "site_name = \"Tumbarumba\"\n",
      "site_latitude = bom_sites_info[site_name][\"latitude\"]\n",
      "site_longitude = bom_sites_info[site_name][\"longitude\"]\n",
      "site_elevation = bom_sites_info[site_name][\"elevation\"]\n",
      "site_number_list = bom_sites_info[site_name].keys()\n",
      "for item in [\"latitude\",\"longitude\",\"elevation\"]:\n",
      "    if item in site_number_list: site_number_list.remove(item)\n",
      "data_dict = {}\n",
      "for idx,sn in enumerate(site_number_list):\n",
      "    csvname = [fn for fn in file_list if str(sn) in fn]\n",
      "    # columns are:\n",
      "    # file data content\n",
      "    #  1    0    station number\n",
      "    #  7    1    year, local standard time\n",
      "    #  8    2    month, local standard time\n",
      "    #  9    3    day, local standard time\n",
      "    #  10   4    hour, local standard time\n",
      "    #  11   5    minute, local standard time\n",
      "    #  12   6    precip since 0900\n",
      "    #  14   7    air temperature, C\n",
      "    #  16   8    dew point temperature, C\n",
      "    #  18   9    relative humidity, %\n",
      "    #  20   10   wind speed, m/s\n",
      "    #  22   11   wind direction, degT\n",
      "    #  24   12   gust in last 10 minutes, m/s\n",
      "    #  26   13   station pressure, hPa\n",
      "    data=numpy.genfromtxt(csvname[0],skip_header=1,delimiter=\",\",usecols=(1,7,8,9,10,11,12,14,16,18,20,22,24,26),\n",
      "                          missing_values=-9999,filling_values=-9999)\n",
      "    data = numpy.ma.masked_equal(data,float(-9999),copy=True)\n",
      "    data_dict[sn] = data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a dictionary containing the data structures\n",
      "ds_dict = {}\n",
      "for bom_id in data_dict.keys():\n",
      "    ds=qcio.DataStructure()\n",
      "    # put the year, month, day, hour and minute into the data structure\n",
      "    nRecs = data_dict[bom_id].shape[0]\n",
      "    ds.globalattributes[\"nc_nrecs\"] = nRecs\n",
      "    ds.globalattributes[\"latitude\"] = bom_sites_info[site_name][str(bom_id)][\"latitude\"]\n",
      "    ds.globalattributes[\"longitude\"] = bom_sites_info[site_name][str(bom_id)][\"longitude\"]\n",
      "    flag = numpy.zeros(nRecs,dtype=numpy.int32)\n",
      "    Seconds = numpy.zeros(nRecs,dtype=numpy.float64)\n",
      "    qcutils.CreateSeries(ds,'Year',data_dict[bom_id][:,1],Flag=flag,Attr=qcutils.MakeAttributeDictionary(long_name='Year',units='none'))\n",
      "    qcutils.CreateSeries(ds,'Month',data_dict[bom_id][:,2],Flag=flag,Attr=qcutils.MakeAttributeDictionary(long_name='Month',units='none'))\n",
      "    qcutils.CreateSeries(ds,'Day',data_dict[bom_id][:,3],Flag=flag,Attr=qcutils.MakeAttributeDictionary(long_name='Day',units='none'))\n",
      "    qcutils.CreateSeries(ds,'Hour',data_dict[bom_id][:,4],Flag=flag,Attr=qcutils.MakeAttributeDictionary(long_name='Hour',units='none'))\n",
      "    qcutils.CreateSeries(ds,'Minute',data_dict[bom_id][:,5],Flag=flag,Attr=qcutils.MakeAttributeDictionary(long_name='Minute',units='none'))\n",
      "    qcutils.CreateSeries(ds,'Second',Seconds,Flag=flag,Attr=qcutils.MakeAttributeDictionary(long_name='Second',units='none'))\n",
      "    # now get the Python datetime\n",
      "    qcutils.get_datetimefromymdhms(ds)\n",
      "    ldt = ds.series[\"DateTime\"][\"Data\"]\n",
      "    year = ds.series[\"Year\"][\"Data\"]\n",
      "    month = ds.series[\"Month\"][\"Data\"]\n",
      "    day = ds.series[\"Day\"][\"Data\"]\n",
      "    hour = ds.series[\"Hour\"][\"Data\"]\n",
      "    minute = ds.series[\"Minute\"][\"Data\"]\n",
      "    #print bom_id,ldt[-1],year[-1],month[-1],day[-1],hour[-1],minute[-1]\n",
      "    # now put the data into the data structure\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Precipitation since 0900',units='mm')\n",
      "    qcutils.CreateSeries(ds,'Precip',data_dict[bom_id][:,6],Flag=flag,Attr=attr)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Air temperature',units='C')\n",
      "    qcutils.CreateSeries(ds,'Ta',data_dict[bom_id][:,7],Flag=flag,Attr=attr)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Dew point temperature',units='C')\n",
      "    qcutils.CreateSeries(ds,'Td',data_dict[bom_id][:,8],Flag=flag,Attr=attr)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Relative humidity',units='%')\n",
      "    qcutils.CreateSeries(ds,'RH',data_dict[bom_id][:,9],Flag=flag,Attr=attr)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Wind speed',units='m/s')\n",
      "    qcutils.CreateSeries(ds,'Ws',data_dict[bom_id][:,10],Flag=flag,Attr=attr)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Wind direction',units='degT')\n",
      "    qcutils.CreateSeries(ds,'Wd',data_dict[bom_id][:,11],Flag=flag,Attr=attr)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Wind gust',units='m/s')\n",
      "    qcutils.CreateSeries(ds,'Wd',data_dict[bom_id][:,12],Flag=flag,Attr=attr)\n",
      "    data_dict[bom_id][:,13] = data_dict[bom_id][:,13]/float(10)\n",
      "    attr=qcutils.MakeAttributeDictionary(long_name='Air Pressure',units='kPa')\n",
      "    qcutils.CreateSeries(ds,'ps',data_dict[bom_id][:,13],Flag=flag,Attr=attr)\n",
      "    # now interpolate\n",
      "    for label in [\"Precip\",\"Ta\",\"Td\",\"RH\",\"Ws\",\"Wd\",\"ps\"]:\n",
      "        qcts.InterpolateOverMissing(ds,series=label,maxlen=2)\n",
      "    # put this stations data into the data structure dictionary\n",
      "    ds_dict[bom_id] = ds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the earliest start datetime and the latest end datetime\n",
      "bom_id_list = ds_dict.keys()\n",
      "ds0 = ds_dict[bom_id_list[0]]\n",
      "ldt = ds0.series[\"DateTime\"][\"Data\"]\n",
      "#print bom_id_list[0],\":\",ldt[0],ldt[-1]\n",
      "start_date = ldt[0]\n",
      "end_date = ldt[-1]\n",
      "bom_id_list.remove(bom_id_list[0])\n",
      "for bom_id in bom_id_list:\n",
      "    dsn = ds_dict[bom_id]\n",
      "    ldtn = dsn.series[\"DateTime\"][\"Data\"]\n",
      "    #print bom_id,\":\",ldtn[0],ldtn[-1]\n",
      "    start_date = min([start_date,ldtn[0]])\n",
      "    end_date = max([end_date,ldtn[-1]])\n",
      "#print start_date,end_date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# merge the individual data structures into a single one\n",
      "ds_all = qcio.DataStructure()\n",
      "ds_all.globalattributes[\"time_step\"] = 30\n",
      "ds_all.globalattributes[\"site_name\"] = site_name\n",
      "ds_all.globalattributes[\"latitude\"] = site_latitude\n",
      "ds_all.globalattributes[\"longitude\"] = site_longitude\n",
      "ds_all.globalattributes[\"elevation\"] = site_elevation\n",
      "ts = int(ds_all.globalattributes[\"time_step\"])\n",
      "ldt_all = [result for result in qcutils.perdelta(start_date,end_date,datetime.timedelta(minutes=ts))]\n",
      "nRecs = len(ldt_all)\n",
      "ds_all.globalattributes[\"nc_nrecs\"] = nRecs\n",
      "ds_all.series[\"DateTime\"] = {}\n",
      "ds_all.series[\"DateTime\"][\"Data\"] = ldt_all\n",
      "flag = numpy.zeros(nRecs,dtype=numpy.int32)\n",
      "ds_all.series[\"DateTime\"][\"Flag\"] = flag\n",
      "ds_all.series[\"DateTime\"][\"Attr\"] = {}\n",
      "ds_all.series['DateTime'][\"Attr\"][\"long_name\"] = \"Date-time object\"\n",
      "ds_all.series['DateTime'][\"Attr\"][\"units\"] = \"None\"\n",
      "# get the year, month, day, hour, minute and seconds from the Python datetime\n",
      "qcutils.get_ymdhms_from_datetime(ds_all)\n",
      "# get the xlDateTime from the \n",
      "xlDateTime = qcutils.get_xldate_from_datetime(ldt_all,datemode=0)\n",
      "attr = qcutils.MakeAttributeDictionary(long_name=\"Date/time in Excel format\",units=\"days since 1899-12-31 00:00:00\")\n",
      "qcutils.CreateSeries(ds_all,\"xlDateTime\",xlDateTime,Flag=flag,Attr=attr)\n",
      "# loop over the stations\n",
      "for idx,bom_id in enumerate(ds_dict.keys()):\n",
      "    ds = ds_dict[bom_id]\n",
      "    ldt = ds.series[\"DateTime\"][\"Data\"]\n",
      "    index = qcutils.find_indices(ldt_all,ldt)\n",
      "    # loop over the variables\n",
      "    for label in [\"Precip\",\"Ta\",\"Td\",\"RH\",\"Ws\",\"Wd\",\"ps\"]:\n",
      "        data_all = numpy.ma.ones(nRecs,dtype=numpy.float64)*float(c.missing_value)\n",
      "        flag_all = numpy.zeros(nRecs,dtype=numpy.int32)\n",
      "        data,flag,attr = qcutils.GetSeriesasMA(ds,label)\n",
      "        data_all[index] = data\n",
      "        flag_all[index] = flag\n",
      "        output_label = label+\"_\"+str(idx)\n",
      "        attr[\"bom_id\"] = str(bom_id)\n",
      "        qcutils.CreateSeries(ds_all,output_label,data_all,Flag=flag_all,Attr=attr)\n",
      "# get precipitation per time step\n",
      "# now get precipitation per time step from the interpolated precipitation accumulated over the day\n",
      "precip_list = [x for x in ds_all.series.keys() if (\"Precip\" in x) and (\"_QCFlag\" not in x)]\n",
      "#print precip_list\n",
      "for output_label in precip_list:\n",
      "    accum_24hr,flag,attr = qcutils.GetSeriesasMA(ds_all,output_label)\n",
      "    index = numpy.ma.where(accum_24hr<0.001)[0]\n",
      "    accum_24hr[index] = float(0)\n",
      "    precip = numpy.ma.ediff1d(accum_24hr,to_begin=0)\n",
      "    index = [x for x in range(len(ldt_all)) if (ldt_all[x].hour==8) and (ldt_all[x].minute==30)]\n",
      "    precip[index] = float(0)\n",
      "    index = [x for x in range(len(ldt_all)) if (ldt_all[x].hour==9) and (ldt_all[x].minute==0)]\n",
      "    precip[index] = accum_24hr[index]\n",
      "    attr[\"long_name\"] = \"Precipitation total over time step\"\n",
      "    attr[\"units\"] = \"mm/30 minutes\"\n",
      "    qcutils.CreateSeries(ds_all,output_label,precip,Flag=flag,Attr=attr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now write the data structure to file\n",
      "ncname = \"../../Sites/Tumbarumba/Data/AWS/Tumbarumba_AWS.nc\"\n",
      "ncfile = qcio.nc_open_write(ncname)\n",
      "qcio.nc_write_series(ncfile,ds_all,ndims=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = qcio.nc_read_series(ncname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR:qc.utils:get_UTCfromlocaltime: time_zone not in global attributes, checking elsewhere ...\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xlsxwriter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}