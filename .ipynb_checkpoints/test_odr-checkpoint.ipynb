{
 "metadata": {
  "name": "",
  "signature": "sha256:e2f3f29beefd1f077a9ca53bfaa91fbcc89173d8cc968b2e2b5af6a724e90aae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run basics\n",
      "%matplotlib\n",
      "import scipy.odr\n",
      "import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def linear_function(B,x):\n",
      "    \"\"\"\n",
      "    Purpose:\n",
      "     Linear function for use with orthogonal distance regression.\n",
      "    Usage:\n",
      "     linear = scipy.odr.Model(qcutils.linear_function)\n",
      "     where B is a list of slope and offset values\n",
      "           x is an array of x values\n",
      "    \"\"\"\n",
      "    return B[0]*x + B[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = numpy.arange(0,1000)+500*numpy.random.rand(1000)\n",
      "y = numpy.arange(0,1000)+500*numpy.random.rand(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig=plt.figure()\n",
      "plt.plot(x,y,'b.')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linear = scipy.odr.Model(linear_function)\n",
      "mydata = scipy.odr.Data(x,y)\n",
      "myodr = scipy.odr.ODR(mydata,linear,beta0=[1,0])\n",
      "myoutput = myodr.run()\n",
      "myoutput.pprint()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Beta: [  1.03201009 -30.81500167]\n",
        "Beta Std Error: [  0.02211227  17.80683259]\n",
        "Beta Covariance: [[  2.34221816e-08  -1.75327056e-05]\n",
        " [ -1.75327056e-05   1.51891762e-02]]\n",
        "Residual Variance: 20875.6079062\n",
        "Inverse Condition #: 4.57840336807e-05\n",
        "Reason(s) for Halting:\n",
        "  Sum of squares convergence\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resols = sm.OLS(y,sm.add_constant(x,prepend=False)).fit()\n",
      "print resols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7f0bc1feb190>\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print resols.params[0],resols.params[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.814638519608 131.898870958\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myoutput.beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([  1.03201009, -30.81500167])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}