{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "%run basics\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residuals_RHLRC_D(params,NEE,Fsd,D,D0,weighted,weight_type):\n",
    "    alpha = params[0]\n",
    "    beta = params[1]\n",
    "    k = params[2]\n",
    "    gamma = params[3]\n",
    "    resid = NEE - NEE_RHLRC_D(Fsd,D,alpha,beta,k,D0,gamma)\n",
    "    if weighted:\n",
    "        weights = CalculateWeights(resid,weight_type=weight_type)\n",
    "        return resid*weights\n",
    "    else:\n",
    "        return resid\n",
    "\n",
    "def NEE_RHLRC_D(Fsd,D,alpha,beta,k,D0,gamma):\n",
    "    NEE = -1*GPP_RHLRC_D(Fsd,D,alpha,beta,k,D0) + gamma\n",
    "    return NEE\n",
    "\n",
    "def GPP_RHLRC_D(Fsd,D,alpha,beta,k,D0):\n",
    "    beta = beta*SHD_func_Lasslop(D,k,D0)\n",
    "    GPP = alpha*beta*Fsd/(alpha*Fsd+beta)\n",
    "    return GPP\n",
    "\n",
    "def SHD_func_Lasslop(D,k,D0):\n",
    "    SHD_func = numpy.ones(len(D))\n",
    "    idx = numpy.where(D>D0)[0]\n",
    "    SHD_func[idx] = numpy.exp(-k*(D[idx]-D0))\n",
    "    return SHD_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def irls_leastsq(func,p0,args=(),maxfev=3,weight_type='Huber',mode=\"quiet\"):\n",
    "    weighted = False\n",
    "    popt,pcov = scipy.optimize.leastsq(func,p0,args=args+(weighted,weight_type))\n",
    "    if mode!=\"quiet\":\n",
    "        print 'After non-weighted call to leastsq: ',popt\n",
    "    n=1\n",
    "    weighted = True\n",
    "    while n<=maxfev:\n",
    "        popt,pcov = scipy.optimize.leastsq(func,popt,args=args+(weighted,weight_type))\n",
    "        if mode!=\"quiet\":\n",
    "            print 'Weighted call '+str(n)+' to leastsq: ',popt\n",
    "        n = n + 1\n",
    "    return popt,pcov\n",
    "\n",
    "def CalculateWeights(resid,weight_type='Huber'):\n",
    "    if weight_type.lower()=='tukey':\n",
    "        weights = TukeyBiweight(MAD_scale(resid))\n",
    "    elif weight_type.lower()=='huber':\n",
    "        weights = HuberTWeight(MAD_scale(resid))\n",
    "    elif weight_type.lower()=='ols':\n",
    "        weights = OLSWeight(MAD_scale(resid))\n",
    "    else:\n",
    "        print \"CalculateWeights: Unknown weight type, used Huber's t weight\"\n",
    "        weights = HuberTWeight(MAD_scale(resid))\n",
    "    return weights\n",
    "\n",
    "def TukeyBiweight(x):\n",
    "    return ((numpy.abs(x)<1.0)*(1.0 - x**2)**2)\n",
    "\n",
    "def HuberTWeight(x):\n",
    "    weights = numpy.ones(len(x))\n",
    "    idx = numpy.where(numpy.abs(x)>1.345)[0]\n",
    "    weights[idx] = 1.345/numpy.abs(x[idx])\n",
    "    return weights\n",
    "\n",
    "def OLSWeight(x):\n",
    "    weights = numpy.ones(len(x))\n",
    "    return weights\n",
    "\n",
    "def MAD_scale(resid):\n",
    "    scale = numpy.median(numpy.abs(resid - numpy.median(resid))) / 0.6745\n",
    "    return resid/scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the netCDF file name\n",
    "ncname = \"../Sites/Whroo/Data/Portal/Whroo_L4.nc\"\n",
    "# read the contents into a data structure\n",
    "ds = qcio.nc_read_series(ncname)\n",
    "# get the datetime series\n",
    "dt = ds.series[\"DateTime\"][\"Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open an Excel workbook for the results\n",
    "xlname = ncname.replace(\".nc\",\"_RHLRC_WithD.xls\")\n",
    "xlfile = qcio.xl_open_write(xlname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-01-01 00:30:00 2012-02-01 00:30:00 -9999.0 4.66453968049\n",
      "2012-02-01 00:30:00 2012-03-01 00:30:00 -9999.0 4.74088633084\n",
      "2012-03-01 00:30:00 2012-04-01 00:30:00 -11.6935826479 4.75551291\n",
      "2012-04-01 00:30:00 2012-05-01 00:30:00 -9.76282724968 3.05611074233\n",
      "2012-05-01 00:30:00 2012-06-01 00:30:00 -11.984396948 2.49565144819\n",
      "2012-06-01 00:30:00 2012-07-01 00:30:00 -9999.0 3.3216780672\n",
      "2012-07-01 00:30:00 2012-08-01 00:30:00 -9999.0 3.04056466812\n",
      "2012-08-01 00:30:00 2012-09-01 00:30:00 -9999.0 2.68058810133\n",
      "2012-09-01 00:30:00 2012-10-01 00:30:00 -9999.0 3.09080968471\n",
      "2012-10-01 00:30:00 2012-11-01 00:30:00 -11.597478008 2.86808664161\n",
      "2012-11-01 00:30:00 2012-12-01 00:30:00 -8.85205838693 3.30013662774\n",
      "2012-12-01 00:30:00 2013-01-01 00:30:00 -9.39187758943 3.72260613306\n",
      "2013-01-01 00:30:00 2013-02-01 00:30:00 -8.14584163021 3.1250638846\n",
      "2013-02-01 00:30:00 2013-03-01 00:30:00 -10.6727930837 3.87657602326\n",
      "2013-03-01 00:30:00 2013-04-01 00:30:00 -8.55814435748 3.59519017179\n",
      "2013-04-01 00:30:00 2013-05-01 00:30:00 -9.0358135363 2.18988041342\n",
      "2013-05-01 00:30:00 2013-06-01 00:30:00 -9999.0 2.44051437462\n",
      "2013-06-01 00:30:00 2013-07-01 00:30:00 -9999.0 2.87662376323\n",
      "2013-07-01 00:30:00 2013-08-01 00:30:00 -9999.0 2.46846836576\n",
      "2013-08-01 00:30:00 2013-09-01 00:30:00 -9999.0 2.69387425131\n",
      "2013-09-01 00:30:00 2013-10-01 00:30:00 -9999.0 3.20816824788\n",
      "2013-10-01 00:30:00 2013-11-01 00:30:00 -13.7900777516 3.04143154835\n",
      "2013-11-01 00:30:00 2013-12-01 00:30:00 -16.4342684479 2.85509581868\n",
      "2013-12-01 00:30:00 2014-01-01 00:30:00 -9999.0 3.53227307318\n",
      "2014-01-01 00:30:00 2014-02-01 00:30:00 -11.3724556637 3.71979086604\n",
      "2014-02-01 00:30:00 2014-03-01 00:30:00 -9.31224167081 3.70469710246\n",
      "2014-03-01 00:30:00 2014-04-01 00:30:00 -9999.0 3.0748586345\n",
      "2014-04-01 00:30:00 2014-05-01 00:30:00 -9999.0 3.95147972724\n",
      "2014-05-01 00:30:00 2014-06-01 00:30:00 -9999.0 3.76140544262\n",
      "2014-06-01 00:30:00 2014-07-01 00:30:00 -9999.0 3.30088434826\n",
      "2014-07-01 00:30:00 2014-08-01 00:30:00 -9999.0 2.37555952106\n",
      "2014-08-01 00:30:00 2014-09-01 00:30:00 -9999.0 2.20046806183\n",
      "2014-09-01 00:30:00 2014-10-01 00:30:00 -9999.0 3.15976090208\n",
      "2014-10-01 00:30:00 2014-11-01 00:30:00 -14.9539411357 4.08369871307\n",
      "2014-11-01 00:30:00 2014-12-01 00:30:00 -12.3939988159 3.42377661226\n",
      "2014-12-01 00:30:00 2015-01-01 00:30:00 -9.38109298675 3.5691719222\n",
      "2015-01-01 00:30:00 2015-02-01 00:30:00 -9999.0 4.77839855708\n",
      "2015-02-01 00:30:00 2015-03-01 00:30:00 -8.88553634155 3.70801211016\n",
      "2015-03-01 00:30:00 2015-04-01 00:30:00 -9.04617513634 3.13133032148\n",
      "2015-04-01 00:30:00 2015-05-01 00:30:00 -9999.0 3.10056957965\n",
      "2015-05-01 00:30:00 2015-06-01 00:30:00 -9999.0 2.76461741798\n",
      "2015-06-01 00:30:00 2015-07-01 00:30:00 -9999.0 1.44826137411\n",
      "2015-07-01 00:30:00 2015-08-01 00:30:00 -9999.0 -9999.0\n",
      "2015-08-01 00:30:00 2015-09-01 00:30:00 -9999.0 1.74099734564\n",
      "2015-09-01 00:30:00 2015-10-01 00:30:00 -9999.0 1.54820601388\n"
     ]
    }
   ],
   "source": [
    "# rectangular hyperbolic LRC, with D function\n",
    "# set the downwelling shortwave radiation and friction velocity thresholds\n",
    "Fsd_threshold = 10\n",
    "ustar_threshold = 0.40\n",
    "VPD0 = 1.0\n",
    "# add a sheet to the Excel workbook\n",
    "xlsheet = xlfile.add_sheet(\"RHLRC_WithD\")\n",
    "# get the index of the first period at the start of the first whole month\n",
    "si = qcutils.GetDateIndex(dt,str(dt[0]),match=\"startnextmonth\")\n",
    "# get the start datetime\n",
    "start_date = dt[si]\n",
    "# create a dictionary for the results\n",
    "RHLRC_WithD = {\"DateTime\":{\"data\":[],\"units\":\"-\",\"format\":\"dd/mm/yyyy hh:mm\"},\n",
    "               \"alpha\":{\"data\":[],\"units\":\"-\",\"format\":\"0.0000\"},\n",
    "               \"beta\":{\"data\":[],\"units\":\"-\",\"format\":\"0.00\"},\n",
    "               \"k\":{\"data\":[],\"units\":\"-\",\"format\":\"0.000\"},\n",
    "               \"gamma\":{\"data\":[],\"units\":\"-\",\"format\":\"0.00\"},\n",
    "               \"ER\":{\"data\":[],\"units\":\"-\",\"format\":\"0.00\"}}\n",
    "# loop over periods until done\n",
    "while start_date<dt[-1]:\n",
    "    # get the end datetime for this pass\n",
    "    end_date = start_date+dateutil.relativedelta.relativedelta(months=1)\n",
    "    # indices of start and end datetimes\n",
    "    si = qcutils.GetDateIndex(dt,str(start_date),default=0)\n",
    "    ei = qcutils.GetDateIndex(dt,str(end_date),default=len(dt))\n",
    "    # minimum number of points is 10%\n",
    "    min_points = int(0.1*(ei-si))\n",
    "    mi = int((si+ei)/2)\n",
    "    # get the downwelling shortwave, CO2 flux and friction velocity\n",
    "    Fsd,f,a = qcutils.GetSeriesasMA(ds,\"Fsd\",si=si,ei=ei)\n",
    "    NEE,f,a = qcutils.GetSeriesasMA(ds,\"Fc\",si=si,ei=ei)\n",
    "    ustar,f,a = qcutils.GetSeriesasMA(ds,\"ustar\",si=si,ei=ei)\n",
    "    VPD,f,a = qcutils.GetSeriesasMA(ds,\"VPD\",si=si,ei=ei)\n",
    "    T,f,a = qcutils.GetSeriesasMA(ds,\"T\",si=si,ei=ei)\n",
    "    # mask out the night-time ...\n",
    "    Fsd_day = numpy.ma.masked_where(Fsd<Fsd_threshold,Fsd)\n",
    "    VPD_day = numpy.ma.masked_where(Fsd<Fsd_threshold,VPD)\n",
    "    T_day = numpy.ma.masked_where(Fsd<Fsd_threshold,T)\n",
    "    NEE_day = numpy.ma.masked_where(Fsd<Fsd_threshold,NEE)\n",
    "    # get the mask across all data (one masked ==> all masked)\n",
    "    ones = numpy.ma.ones(len(Fsd))\n",
    "    for item in [Fsd_day,VPD_day,T_day,NEE_day]:\n",
    "        mask = numpy.ma.mask_or(numpy.ma.getmaskarray(ones),\n",
    "                                numpy.ma.getmaskarray(item),\n",
    "                                copy=True)\n",
    "    # remove masked elements\n",
    "    for item in [Fsd_day,VPD_day,T_day,NEE_day]:\n",
    "        item = numpy.ma.compressed(numpy.ma.masked_where(mask,item))\n",
    "    # mask out the day-time conditions ...\n",
    "    NEE_night = numpy.ma.masked_where(Fsd>=Fsd_threshold,NEE)\n",
    "    T_night = numpy.ma.masked_where(Fsd>=Fsd_threshold,T)\n",
    "    # get the mask across all data (one masked ==> all masked)\n",
    "    ones = numpy.ma.ones(len(Fsd))\n",
    "    for item in [NEE_night,T_night]:\n",
    "        mask = numpy.ma.mask_or(numpy.ma.getmaskarray(ones),\n",
    "                                numpy.ma.getmaskarray(item),\n",
    "                                copy=True)\n",
    "    # remove masked elements\n",
    "    for item in [NEE_night,T_night]:\n",
    "        item = numpy.ma.compressed(numpy.ma.masked_where(mask,item))\n",
    "    # add the mid-period datetime to the results dictionary\n",
    "    RHLRC_WithD[\"DateTime\"][\"data\"].append(dt[mi])\n",
    "    # call the optimisation if more than the minimum number of\n",
    "    # points available, otherwise set results to missing value\n",
    "    # set the priors\n",
    "    rb_prior = numpy.ma.mean(NEE_night)\n",
    "    beta_prior = numpy.abs(numpy.percentile(NEE_day,5)-numpy.percentile(NEE_day,95))\n",
    "    print start_date,end_date,numpy.percentile(NEE_day,5),numpy.percentile(NEE_day,95)\n",
    "    p0 = [0.01,20,0,2]\n",
    "    if len(Fsd_day)>=min_points:\n",
    "        #print start_date,end_date,numpy.max(NEE_day),numpy.min(NEE_day)\n",
    "        #print start_date,end_date,numpy.max(Fsd_day),numpy.min(Fsd_day)\n",
    "        #print start_date,end_date,numpy.max(VPD_day),numpy.min(VPD_day)\n",
    "        popt,pcov = irls_leastsq(residuals_RHLRC_D,p0,\n",
    "                                 args=(NEE_day,Fsd_day,VPD_day,VPD0),\n",
    "                                 maxfev=3,weight_type='Huber')\n",
    "    else:\n",
    "        popt = [-9999,-9999,-9999,-9999]\n",
    "    RHLRC_WithD[\"alpha\"][\"data\"].append(popt[0])\n",
    "    RHLRC_WithD[\"beta\"][\"data\"].append(popt[1])\n",
    "    RHLRC_WithD[\"k\"][\"data\"].append(popt[2])\n",
    "    RHLRC_WithD[\"gamma\"][\"data\"].append(popt[3])\n",
    "    # plot the data\n",
    "    if popt[0]!=-9999:\n",
    "        NEE_fit = NEE_RHLRC_D(Fsd_day,VPD_day,popt[0],popt[1],popt[2],VPD0,popt[3])\n",
    "        fig=plt.figure()\n",
    "        plt.plot(Fsd_day,NEE_day,'b.')\n",
    "        plt.plot(Fsd_day,NEE_fit,'r+')\n",
    "        plt.show()\n",
    "    # get the average of the u*-filtered, nocturnal Fc\n",
    "    NEE_night = numpy.ma.masked_where(ustar<=ustar_threshold,NEE_night)\n",
    "    if len(NEE_night)>=min_points:\n",
    "        RHLRC_WithD[\"ER\"][\"data\"].append(numpy.ma.mean(NEE_night))\n",
    "    else:\n",
    "        RHLRC_WithD[\"ER\"][\"data\"].append(-9999)\n",
    "    start_date = end_date\n",
    "# write the results to the Excel workbook\n",
    "qcio.xl_write_data(xlsheet,RHLRC_WithD,xlCol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xlfile.save(xlname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
